{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aashi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment                                        Cust_review\n",
      "0  Positive  bang time smooth flights flew back faro london...\n",
      "1  Positive  good affordable good affordable time pleasant ...\n",
      "2  Positive  really impressed really impressed pay cost £ s...\n",
      "3  Positive  decent offering review faro liverpool booked s...\n",
      "4  Positive  cabin crew welcoming friendly left gate ahead ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load English language model for spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define the list of stopwords\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "                 \n",
    "custom_stopwords = set(['ryanair', 'flight', 'airport', 'us', 'one', 'airline' 'would','get','told', 'could', 'even', 'got', 'also', 'another', 'ever', 'like', 'way', 'go', 'asked', 'every', '2', 'plane'])\n",
    "STOP_WORDS = STOP_WORDS.union(custom_stopwords)\n",
    "\n",
    "# Define the function to expand contractions\n",
    "def expand(x):\n",
    "    \"\"\"Expand contractions in a sentence.\"\"\"\n",
    "    return contractions.fix(x)\n",
    "\n",
    "def cleaning(text):        \n",
    "    # converting to lowercase, removing URL links, special characters, punctuations...\n",
    "    text = text.lower() # converting to lowercase\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # removing URL links\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text) # removing number \n",
    "    text = re.sub('<.*?>+', '', text) # removing special characters, \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # punctuations\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('[’“”…]', '', text)\n",
    "   \n",
    "    #removing emoji: \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)   \n",
    "\n",
    "   # removing short form: \n",
    "    \n",
    "    text=re.sub(\"isn't\",'is not',text)\n",
    "    text=re.sub(\"he's\",'he is',text)\n",
    "    text=re.sub(\"wasn't\",'was not',text)\n",
    "    text=re.sub(\"there's\",'there is',text)\n",
    "    text=re.sub(\"couldn't\",'could not',text)\n",
    "    text=re.sub(\"won't\",'will not',text)\n",
    "    text=re.sub(\"they're\",'they are',text)\n",
    "    text=re.sub(\"she's\",'she is',text)\n",
    "    text=re.sub(\"There's\",'there is',text)\n",
    "    text=re.sub(\"wouldn't\",'would not',text)\n",
    "    text=re.sub(\"haven't\",'have not',text)\n",
    "    text=re.sub(\"That's\",'That is',text)\n",
    "    text=re.sub(\"you've\",'you have',text)\n",
    "    text=re.sub(\"He's\",'He is',text)\n",
    "    text=re.sub(\"what's\",'what is',text)\n",
    "    text=re.sub(\"weren't\",'were not',text)\n",
    "    text=re.sub(\"we're\",'we are',text)\n",
    "    text=re.sub(\"hasn't\",'has not',text)\n",
    "    text=re.sub(\"you'd\",'you would',text)\n",
    "    text=re.sub(\"shouldn't\",'should not',text)\n",
    "    text=re.sub(\"let's\",'let us',text)\n",
    "    text=re.sub(\"they've\",'they have',text)\n",
    "    text=re.sub(\"You'll\",'You will',text)\n",
    "    text=re.sub(\"i'm\",'i am',text)\n",
    "    text=re.sub(\"we've\",'we have',text)\n",
    "    text=re.sub(\"it's\",'it is',text)\n",
    "    text=re.sub(\"don't\",'do not',text)\n",
    "    text=re.sub(\"that´s\",'that is',text)\n",
    "    text=re.sub(\"I´m\",'I am',text)\n",
    "    text=re.sub(\"it’s\",'it is',text)\n",
    "    text=re.sub(\"she´s\",'she is',text)\n",
    "    text=re.sub(\"he’s'\",'he is',text)\n",
    "    text=re.sub('I’m','I am',text)\n",
    "    text=re.sub('I’d','I did',text)\n",
    "    text=re.sub(\"he’s'\",'he is',text)\n",
    "    text=re.sub('there’s','there is',text)\n",
    "    \n",
    "     \n",
    "    return text\n",
    "\n",
    "\n",
    "# Define the function to remove accented characters\n",
    "def remove_accented_chars(x):\n",
    "    \"\"\"Remove accented characters from a sentence.\"\"\"\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x\n",
    "\n",
    "# Define the function to lemmatize words\n",
    "def make_to_base(x):\n",
    "    \"\"\"Lemmatize words in a sentence.\"\"\"\n",
    "    x_list = []\n",
    "    doc = nlp(x)\n",
    "    for token in doc:\n",
    "        lemma = str(token.lemma_)\n",
    "        # Retain original text for pronouns and 'be'\n",
    "        if lemma == '-PRON-' or lemma == 'be':\n",
    "            lemma = token.text\n",
    "        x_list.append(lemma)\n",
    "    return \" \".join(x_list)\n",
    "\n",
    "# # Define the preprocessing function\n",
    "# def preprocess(df, d):\n",
    "#     \"\"\"Preprocess a given document.\"\"\"\n",
    "#     df[d] = df[d].apply(lambda x: x.lower())\n",
    "#     df[d] = df[d].apply(expand)\n",
    "#     df[d] = df[d].apply(lambda x: re.sub('[^A-Za-z0-9\\s-]+', '', x))\n",
    "#     df[d] = df[d].apply(lambda x: \" \".join(x.split()))\n",
    "#     df[d] = df[d].apply(remove_accented_chars)\n",
    "#     df[d] = df[d].apply(make_to_base)\n",
    "#     df[d] = df[d].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
    "\n",
    "#     # Count the frequency of each word\n",
    "#     word_counts = Counter(\" \".join(df[d]).split())\n",
    "    \n",
    "#     # Identify the top 5 most frequent words\n",
    "#     top_5_words = [word for word, _ in word_counts.most_common(10)]\n",
    "    \n",
    "#     print(top_5_words)\n",
    "\n",
    "#     # Remove the top 5 most frequent words\n",
    "#     df[d] = df[d].apply(lambda x: \" \".join([t for t in x.split() if t not in top_5_words]))\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\aashi\\\\Desktop\\\\GA Tech docs\\\\Seventh Sem Spring 24\\\\ISYE 6740 - Computational Data Analysis\\\\Project\\\\Our Project\\\\data\\\\data\\\\ryanair_reviews_sentiments_v1.csv')\n",
    "\n",
    "# Selecting only columns 'A' and 'B'\n",
    "df_selected_cols = df[['Comment title', 'Comment', 'Sentiment']]\n",
    "\n",
    "# Combine two columns with a period in between\n",
    "df_selected_cols['Review'] = df_selected_cols['Comment title'] + '. ' + df_selected_cols['Comment']\n",
    "\n",
    "# Drop the 'first_part' and 'second_part' columns\n",
    "df_selected_cols = df_selected_cols.drop(['Comment title', 'Comment'], axis=1)\n",
    "\n",
    "# # Preprocess the comments\n",
    "# preprocess(df_selected_cols, 'Review')\n",
    "\n",
    "df_selected_cols['Review'] = df_selected_cols['Review'].apply(cleaning)\n",
    "\n",
    "# remove stop word: \n",
    "df_selected_cols['Cust_review'] = df_selected_cols['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (STOP_WORDS)]))\n",
    "\n",
    "df_selected_cols = df_selected_cols[df_selected_cols.Sentiment != 'Neutral'].drop(columns=['Review'])\n",
    "\n",
    "print(df_selected_cols.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1420\n",
       "Negative     804\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df_selected_cols[df_selected_cols['Sentiment']=='Negative'])\n",
    "\n",
    "df_selected_cols['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time</td>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boarding</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>staff</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airline</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pay</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>check</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>service</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>would</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crew</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0      time   1362\n",
       "1  customer   1208\n",
       "2  boarding   1161\n",
       "3     staff    991\n",
       "4   airline    953\n",
       "5       pay    929\n",
       "6     check    916\n",
       "7   service    885\n",
       "8     would    880\n",
       "9      crew    772"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Working with the most Frequent Words: \n",
    "# from collections import Counter\n",
    "# cnt = Counter()\n",
    "# for text in df_selected_cols[\"no_sw\"].values:\n",
    "#     for word in text.split():\n",
    "#         cnt[word] += 1\n",
    "# cnt.most_common(10)\n",
    "# temp = pd.DataFrame(cnt.most_common(10))\n",
    "# temp.columns=['word', 'count']\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "      <th>no_sw</th>\n",
       "      <th>wo_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>bang on time and smooth flights flew back from...</td>\n",
       "      <td>bang time smooth flights flew back faro london...</td>\n",
       "      <td>bang smooth flights flew back faro london luto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>another good affordable flight another good af...</td>\n",
       "      <td>another good affordable flight another good af...</td>\n",
       "      <td>another good affordable another good affordabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>really impressed really impressed you get what...</td>\n",
       "      <td>really impressed really impressed get pay flig...</td>\n",
       "      <td>really impressed really impressed get cost £ s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>a decent offering from ryanair i should like t...</td>\n",
       "      <td>decent offering ryanair like review flight far...</td>\n",
       "      <td>decent offering like review faro liverpool boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>cabin crew were welcoming and friendly flight ...</td>\n",
       "      <td>cabin crew welcoming friendly flight left gate...</td>\n",
       "      <td>cabin crew welcoming friendly left gate ahead ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                             Review  \\\n",
       "0  Positive  bang on time and smooth flights flew back from...   \n",
       "1  Positive  another good affordable flight another good af...   \n",
       "2  Positive  really impressed really impressed you get what...   \n",
       "3  Positive  a decent offering from ryanair i should like t...   \n",
       "4  Positive  cabin crew were welcoming and friendly flight ...   \n",
       "\n",
       "                                               no_sw  \\\n",
       "0  bang time smooth flights flew back faro london...   \n",
       "1  another good affordable flight another good af...   \n",
       "2  really impressed really impressed get pay flig...   \n",
       "3  decent offering ryanair like review flight far...   \n",
       "4  cabin crew welcoming friendly flight left gate...   \n",
       "\n",
       "                                         wo_stopfreq  \n",
       "0  bang smooth flights flew back faro london luto...  \n",
       "1  another good affordable another good affordabl...  \n",
       "2  really impressed really impressed get cost £ s...  \n",
       "3  decent offering like review faro liverpool boo...  \n",
       "4  cabin crew welcoming friendly left gate ahead ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove the most frequent words:\n",
    "# FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "# def remove_freqwords(text):\n",
    "#     \"\"\"custom function to remove the frequent words\"\"\"\n",
    "#     return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "# df_selected_cols[\"wo_stopfreq\"] = df_selected_cols[\"no_sw\"].apply(lambda text: remove_freqwords(text))\n",
    "# df_selected_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Cust_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bang time smooth flights flew back faro london...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>good affordable good affordable time pleasant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>really impressed really impressed pay cost £ s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>decent offering review faro liverpool booked s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>cabin crew welcoming friendly left gate ahead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>1</td>\n",
       "      <td>customer review daughter took holiday kos neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>0</td>\n",
       "      <td>customer review stansted pula tried adhere rul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>1</td>\n",
       "      <td>customer review printing boarding tickets outb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>1</td>\n",
       "      <td>customer review budapest manchester back month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>1</td>\n",
       "      <td>customer review stansted barcelona fine going ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                        Cust_review\n",
       "0             1  bang time smooth flights flew back faro london...\n",
       "1             1  good affordable good affordable time pleasant ...\n",
       "2             1  really impressed really impressed pay cost £ s...\n",
       "3             1  decent offering review faro liverpool booked s...\n",
       "4             1  cabin crew welcoming friendly left gate ahead ...\n",
       "...         ...                                                ...\n",
       "2244          1  customer review daughter took holiday kos neve...\n",
       "2245          0  customer review stansted pula tried adhere rul...\n",
       "2246          1  customer review printing boarding tickets outb...\n",
       "2247          1  customer review budapest manchester back month...\n",
       "2248          1  customer review stansted barcelona fine going ...\n",
       "\n",
       "[2224 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the cleaned data for the train-test split:\n",
    "df_selected_cols.columns=['Sentiment','Cust_review']\n",
    "df_selected_cols.Sentiment = [0 if each == \"Negative\" else 1 for each in df_selected_cols.Sentiment]\n",
    "df_selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bang, time, smooth, flights, flew, back, faro...\n",
       "1    [good, affordable, good, affordable, time, ple...\n",
       "2    [really, impressed, really, impressed, pay, co...\n",
       "3    [decent, offering, review, faro, liverpool, bo...\n",
       "4    [cabin, crew, welcoming, friendly, left, gate,...\n",
       "Name: Cust_review, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_review=df_selected_cols['Cust_review'].apply(lambda x: x.split())\n",
    "tokenized_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(df_selected_cols['Cust_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Get the number of rows (observations) in the sparse matrix\n",
    "num_rows = text_counts.shape[0]\n",
    "\n",
    "# Create shuffled indices\n",
    "shuffled_indices = np.random.permutation(num_rows)\n",
    "\n",
    "# Use shuffled indices to shuffle the data\n",
    "X_shuffled = text_counts[shuffled_indices]\n",
    "y_shuffled = df_selected_cols['Sentiment'].iloc[shuffled_indices]\n",
    "\n",
    "# Split the shuffled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    286\n",
       "0    159\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB model accuracy is 74.61%\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      "     0    1\n",
      "0  103   56\n",
      "1   57  229\n",
      "------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65       159\n",
      "           1       0.80      0.80      0.80       286\n",
      "\n",
      "    accuracy                           0.75       445\n",
      "   macro avg       0.72      0.72      0.72       445\n",
      "weighted avg       0.75      0.75      0.75       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "CNB = ComplementNB()\n",
    "CNB.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "predicted = CNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, y_test)\n",
    "\n",
    "print('ComplementNB model accuracy is',str('{:04.2f}'.format(accuracy_score*100))+'%')\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))\n",
    "print('------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinominalNB model accuracy is 73.71%\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      "    0    1\n",
      "0  98   61\n",
      "1  56  230\n",
      "------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63       159\n",
      "           1       0.79      0.80      0.80       286\n",
      "\n",
      "    accuracy                           0.74       445\n",
      "   macro avg       0.71      0.71      0.71       445\n",
      "weighted avg       0.74      0.74      0.74       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, y_test)\n",
    "\n",
    "print('MultinominalNB model accuracy is',str('{:04.2f}'.format(accuracy_score*100))+'%')\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))\n",
    "print('------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB model accuracy = 69.21%\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      "    0    1\n",
      "0  74   85\n",
      "1  52  234\n",
      "------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.52       159\n",
      "           1       0.73      0.82      0.77       286\n",
      "\n",
      "    accuracy                           0.69       445\n",
      "   macro avg       0.66      0.64      0.65       445\n",
      "weighted avg       0.68      0.69      0.68       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, y_train)\n",
    "\n",
    "predicted = BNB.predict(X_test)\n",
    "accuracy_score_bnb = metrics.accuracy_score(predicted,y_test)\n",
    "\n",
    "print('BernoulliNB model accuracy = ' + str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))\n",
    "print('------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
